{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:07<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of channels : tensor([15.3524, 15.3524, 15.3524])\n",
      "tensor([15.3524, 15.3524, 15.3524]) tensor([4.8512, 4.8512, 4.8512]) 52\n",
      "Mean : tensor([0.2952, 0.2952, 0.2952]), Std:tensor([0.9554, 0.9554, 0.9554])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Normalize.__init__() got an unexpected keyword argument 'inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# normalization(0~1) of dataset images\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# normalization이 필요할까 모르겠다\u001b[39;00m\n\u001b[0;32m     57\u001b[0m stats \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtuple\u001b[39m(mean\u001b[38;5;241m.\u001b[39mtolist()), \u001b[38;5;28mtuple\u001b[39m(std\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m---> 58\u001b[0m train_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(), \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m])\n\u001b[0;32m     60\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ImageFolder(TRAIN_DATASET_PATH\u001b[38;5;241m.\u001b[39mas_posix(), train_transform)\n\u001b[0;32m     61\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mDATA_BATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Normalize.__init__() got an unexpected keyword argument 'inplace'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Surface Defect Detection with Convolutional Auto-Encoder Model\n",
    "'''\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "Train/Test Data Preparation\n",
    "'''\n",
    "# normal dataset path\n",
    "TRAIN_DATASET_PATH = pathlib.Path(os.path.dirname(os.path.realpath('__file__'))).parent.parent / \"dataset\" / \"SDD\" / \"luxteel\" / \"ae_dataset\" / \"train\"\n",
    "TEST_DATASET_PATH = pathlib.Path(os.path.dirname(os.path.realpath('__file__'))).parent.parent / \"dataset\" / \"SDD\" / \"luxteel\" / \"ae_dataset\" / \"train\" / \"normal\"\n",
    "\n",
    "# read list of files(only names)\n",
    "normal_image_files = os.listdir(TRAIN_DATASET_PATH.as_posix())\n",
    "print(f\"Number of Data : {len(normal_image_files)}\")\n",
    "\n",
    "# set dataloader\n",
    "DATA_BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.01\n",
    "GRAD_CLIP = 0.12\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "dataset = ImageFolder(TRAIN_DATASET_PATH, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=DATA_BATCH_SIZE)\n",
    "\n",
    "\n",
    "# calc mean and std for image normalization\n",
    "_sum_channels = 0\n",
    "_squared_sum_channels = 0\n",
    "_total_batches = 0\n",
    "\n",
    "for data, _ in tqdm(dataloader):\n",
    "    _sum_channels += torch.mean(data, dim=[0,2,3]) # calc mean for each channels (dim=Batch, Channel, Height, Width)\n",
    "    _squared_sum_channels += torch.mean(data**2, dim=[0,2,3])\n",
    "    _total_batches += 1\n",
    "\n",
    "mean = _sum_channels / _total_batches\n",
    "std = (_squared_sum_channels / _squared_sum_channels - mean ** 2) ** 0.5\n",
    "print(_sum_channels, _squared_sum_channels, _total_batches)\n",
    "print(f\"Mean : {mean}, Std:{std}\")\n",
    "\n",
    "\n",
    "# normalization(0~1) of dataset images\n",
    "# normalization이 필요할까 모르겠다\n",
    "stats = (tuple(mean.tolist()), tuple(std.tolist()))\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(*stats, inplace=True)])\n",
    "\n",
    "train_dataset = ImageFolder(TRAIN_DATASET_PATH.as_posix(), train_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=DATA_BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (latent): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (deconv1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): UpsamplingNearest2d(scale_factor=2.0, mode='nearest')\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (deconv2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): UpsamplingNearest2d(scale_factor=2.0, mode='nearest')\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (deconv3): Sequential(\n",
      "    (0): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): UpsamplingNearest2d(scale_factor=2.0, mode='nearest')\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Convolutional AE Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    \n",
    "    @staticmethod\n",
    "    def __conv_block(in_channels, out_channels, pool=False):\n",
    "        # output dim and input dim are the same (kernel size=3, padding=1)\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm2d(num_features=out_channels), nn.ReLU(inplace=True)]\n",
    "        if pool: \n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))  # max pooling with 2 dim kernel\n",
    "        return nn.Sequential(*layers) # combine into single block\n",
    "    \n",
    "    @staticmethod\n",
    "    def __deconv_block(in_channels, out_channels, pool=False):\n",
    "        # output dim and input dim are the same (kernel size=3, padding=1)\n",
    "        layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm2d(num_features=out_channels), nn.ReLU(inplace=True), nn.UpsamplingNearest2d(out_channels, scale_factor=2)]\n",
    "        if pool: \n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))  # max pooling with 2 dim kernel\n",
    "        return nn.Sequential(*layers) # combine into single block\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # encoder layer\n",
    "        self._encoding_dim = 256\n",
    "        self.conv1 = self.__conv_block(channels, 64, pool=True)\n",
    "        self.conv2 = self.__conv_block(64, 128, pool=True)\n",
    "        self.conv3 = self.__conv_block(128, 256, pool=True)\n",
    "        self.latent = nn.Sequential(nn.Flatten(),\n",
    "                                    nn.Linear(256, self._encoding_dim),\n",
    "                                    nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.deconv1 = self.__deconv_block(256, 128, pool=True)\n",
    "        self.deconv2 = self.__deconv_block(128, 64, pool=True)\n",
    "        self.deconv3 = self.__deconv_block(64, channels, pool=True)\n",
    "        \n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        \n",
    "        # encoder\n",
    "        x = self.conv1(x_in)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.latent(x)\n",
    "        encoded = x\n",
    "        \n",
    "        # decoder\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "#model = ConvAutoencoder(3)\n",
    "\n",
    "# device selection function (GPU, CPU, MPS for MacOS)\n",
    "def get_device_use():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_device_use()\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "model = to_device(ConvAutoencoder(channels=3), device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),LEARNING_RATE,amsgrad=True, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_BATCH_SIZE = 10\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.01\n",
    "GRAD_CLIP = 0.12\n",
    "WEIGHT_DECAY = 0.0001\n",
    "\n",
    "DATASET_PATH = pathlib.Path(os.path.dirname(os.path.realpath('__file__'))).parent.parent / \"dataset\" / \"SDD\" / \"luxteel\" / \"resnet_dataset\"\n",
    "\n",
    "TRAIN_DATASET_PATH = pathlib.Path(os.path.dirname(os.path.realpath('__file__'))).parent.parent / \"dataset\" / \"SDD\" / \"luxteel\" / \"resnet_dataset\" / \"train\" / \"normal\"\n",
    "TEST_DATASET_PATH = pathlib.Path(os.path.dirname(os.path.realpath('__file__'))).parent.parent / \"dataset\" / \"SDD\" / \"luxteel\" / \"resnet_dataset\" / \"test\"\n",
    "\n",
    "#defect_image_files = os.listdir(DEFECT_DATASET_PATH.as_posix())\n",
    "normal_image_files = os.listdir(TRAIN_DATASET_PATH.as_posix())\n",
    "\n",
    "# random shuffle\n",
    "#random.shuffle(defect_image_files)\n",
    "#random.shuffle(normal_image_files)\n",
    "\n",
    "# split dataset\n",
    "trainset_rate = 0.7\n",
    "#defect_train_size = int(trainset_rate*len(defect_image_files))\n",
    "normal_train_size = int(trainset_rate*len(normal_image_files))\n",
    "\n",
    "\n",
    "dataset = ImageFolder(TRAIN_DATASET_PATH, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=DATA_BATCH_SIZE)\n",
    "\n",
    "# calc mean and std for image normalization\n",
    "_sum_channels = 0\n",
    "_squared_sum_channels =0\n",
    "_total_batches = 0\n",
    "\n",
    "for data, _ in tqdm(dataloader):\n",
    "    _sum_channels += torch.mean(data, dim=[0,2,3]) # calc mean for each channels (dim=Batch, Channel, Height, Width)\n",
    "    _squared_sum_channels += torch.mean(data**2, dim=[0,2,3])\n",
    "    _total_batches += 1\n",
    "mean = _sum_channels / _total_batches\n",
    "std = (_squared_sum_channels / _squared_sum_channels - mean ** 2) ** 0.5\n",
    "\n",
    "print(_sum_channels, _squared_sum_channels, _total_batches)\n",
    "print(f\"Mean : {mean}, Std:{std}\")\n",
    "\n",
    "# normalization(0~1) of dataset images\n",
    "stats = (tuple(mean.tolist()), tuple(std.tolist()))\n",
    "train_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(*stats, inplace=True)])\n",
    "\n",
    "train_dataset = ImageFolder((DATASET_PATH/\"train\").as_posix(), train_transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=DATA_BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "# device selection function (GPU, CPU, MPS for MacOS)\n",
    "def get_device_use():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_device_use()\n",
    "print(f\"Selected Device : {device}\")\n",
    "\n",
    "# transfer data into the selected device\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dataloader, device) -> None:\n",
    "        self.__dataloader = dataloader\n",
    "        self.__device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.__dataloader:\n",
    "            yield to_device(b, self.__device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.__dataloader)\n",
    "    \n",
    "train_dataloader = DeviceDataLoader(train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (t_conv1): ConvTranspose2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv2): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# convolutional auto encoder model impl.\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # encoder layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1) # depth 3 -> 16\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=4, kernel_size=3, padding=1) # depth 16 -> 4\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # decoder layer\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        \n",
    "        # encode\n",
    "        x = F.relu(self.conv1(x_in))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #decode\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        # no need to flatten images\n",
    "        images, _ = data\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, images)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
